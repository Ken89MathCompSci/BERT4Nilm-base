{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyP6+sgIrwsx0ebhJEo6cFR5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ken89MathCompSci/BERT4Nilm-base/blob/kengoh-corrected-parameters-fridge-and-washer/BERT4NILM-corrected-parameters-fridge-and-washer-18-September-2025.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "860pZ3stQwtq",
        "outputId": "37ab94a8-9568-40fb-9df9-ed5544e3e153"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mBERT4Nilm-base\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ],
      "source": [
        "ls\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "hGklx2qPRTRl",
        "outputId": "ac24b19b-241b-4a73-97a8-16d4a5f072e8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import fileinput\n",
        "\n",
        "trainer_file = '/content/BERT4Nilm-base/trainer.py'\n",
        "\n",
        "# Use a more robust in-place replacement with python\n",
        "with fileinput.FileInput(trainer_file, inplace=True, backup='.bak') as file:\n",
        "    for line in file:\n",
        "        # Remove the deprecated import\n",
        "        if 'from torch.autograd.gradcheck import zero_gradients' in line:\n",
        "            continue # Skip printing this line\n",
        "        # Replace the deprecated function call with the optimizer's zero_grad() method\n",
        "        elif 'zero_gradients(self.model.cpu().parameters())' in line:\n",
        "            # It's important to preserve indentation\n",
        "            indentation = line[:len(line) - len(line.lstrip())]\n",
        "            print(f\"{indentation}self.optim.zero_grad()\");\n",
        "        else:\n",
        "            print(line, end='')\n",
        "\n",
        "print(f\"Patched {trainer_file} to fix the 'zero_gradients' ImportError.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5x31kro0RVyB",
        "outputId": "5941842c-7bd6-4d2f-f9ec-76b7ffb3e2e5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Patched /content/BERT4Nilm-base/trainer.py to fix the 'zero_gradients' ImportError.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('/content/BERT4Nilm-base/dataset.py', 'r') as f:\n",
        "    content = f.read()\n",
        "\n",
        "# Correct the deprecated pandas '.append' method\n",
        "# This handles all the broken states we've seen so far\n",
        "content = content.replace('_entire_data._append', 'entire_data._append') # As seen in the last error\n",
        "content = content.replace('_entire_data.append', 'entire_data._append') # From the first failed fix\n",
        "content = content.replace('entire_data.append', 'entire_data._append')  # Original state\n",
        "\n",
        "# Correct the deprecated '.fillna' method\n",
        "content = content.replace(\".fillna(method='ffill')\", \".ffill()\")\n",
        "\n",
        "with open('/content/BERT4Nilm-base/dataset.py', 'w') as f:\n",
        "    f.write(content)\n",
        "\n",
        "print(\"dataset.py has been patched (again, with feeling).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bFXoPVbPRWuu",
        "outputId": "d669ab5a-1528-44e7-dcab-83182b1e32da"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset.py has been patched (again, with feeling).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU is available.\")\n",
        "    # List all available GPUs and their IDs\n",
        "    for i in range(torch.cuda.device_count()):\n",
        "        print(f\"GPU ID: {i}, Name: {torch.cuda.get_device_name(i)}\")\n",
        "else:\n",
        "    print(\"No GPU available. The code will run on CPU.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gxAlz9jRRara",
        "outputId": "9398773c-0348-4aff-823f-8d66ebca182f"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU is available.\n",
            "GPU ID: 0, Name: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cd /content/BERT4Nilm-base && python train.py"
      ],
      "metadata": {
        "id": "nABEqtgaRb1Q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}